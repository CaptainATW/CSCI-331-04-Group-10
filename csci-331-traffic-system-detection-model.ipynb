{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-10-23T22:16:05.898053Z",
     "iopub.status.busy": "2025-10-23T22:16:05.897672Z",
     "iopub.status.idle": "2025-10-23T22:17:52.345706Z",
     "shell.execute_reply": "2025-10-23T22:17:52.343702Z",
     "shell.execute_reply.started": "2025-10-23T22:16:05.898019Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: segmentation-models-pytorch in /opt/homebrew/lib/python3.11/site-packages (0.5.0)\n",
      "Requirement already satisfied: pytorch-lightning in /opt/homebrew/lib/python3.11/site-packages (2.5.5)\n",
      "Requirement already satisfied: albumentations in /opt/homebrew/lib/python3.11/site-packages (2.0.8)\n",
      "Requirement already satisfied: huggingface-hub>=0.24 in /opt/homebrew/lib/python3.11/site-packages (from segmentation-models-pytorch) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /opt/homebrew/lib/python3.11/site-packages (from segmentation-models-pytorch) (2.1.3)\n",
      "Requirement already satisfied: pillow>=8 in /Users/v/Library/Python/3.11/lib/python/site-packages (from segmentation-models-pytorch) (9.4.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/homebrew/lib/python3.11/site-packages (from segmentation-models-pytorch) (0.6.2)\n",
      "Requirement already satisfied: timm>=0.9 in /opt/homebrew/lib/python3.11/site-packages (from segmentation-models-pytorch) (1.0.20)\n",
      "Requirement already satisfied: torch>=1.8 in /opt/homebrew/lib/python3.11/site-packages (from segmentation-models-pytorch) (2.9.0)\n",
      "Requirement already satisfied: torchvision>=0.9 in /opt/homebrew/lib/python3.11/site-packages (from segmentation-models-pytorch) (0.24.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/homebrew/lib/python3.11/site-packages (from segmentation-models-pytorch) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>5.4 in /opt/homebrew/lib/python3.11/site-packages (from pytorch-lightning) (6.0)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /opt/homebrew/lib/python3.11/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.5.1)\n",
      "Requirement already satisfied: torchmetrics>0.7.0 in /opt/homebrew/lib/python3.11/site-packages (from pytorch-lightning) (1.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/v/Library/Python/3.11/lib/python/site-packages (from pytorch-lightning) (23.0)\n",
      "Requirement already satisfied: typing-extensions>4.5.0 in /opt/homebrew/lib/python3.11/site-packages (from pytorch-lightning) (4.14.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /opt/homebrew/lib/python3.11/site-packages (from pytorch-lightning) (0.15.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /opt/homebrew/lib/python3.11/site-packages (from albumentations) (1.16.2)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /opt/homebrew/lib/python3.11/site-packages (from albumentations) (2.12.3)\n",
      "Requirement already satisfied: albucore==0.0.24 in /opt/homebrew/lib/python3.11/site-packages (from albumentations) (0.0.24)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /opt/homebrew/lib/python3.11/site-packages (from albumentations) (4.12.0.88)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /opt/homebrew/lib/python3.11/site-packages (from albucore==0.0.24->albumentations) (4.2.1)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /opt/homebrew/lib/python3.11/site-packages (from albucore==0.0.24->albumentations) (6.5.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/homebrew/lib/python3.11/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.13.1)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (3.20.0)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2.28.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (1.1.10)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/lib/python3.11/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (78.1.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/lib/python3.11/site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /opt/homebrew/lib/python3.11/site-packages (from pydantic>=2.9.2->albumentations) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/homebrew/lib/python3.11/site-packages (from pydantic>=2.9.2->albumentations) (0.4.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.8->segmentation-models-pytorch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.8->segmentation-models-pytorch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.8->segmentation-models-pytorch) (3.1.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (22.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.22.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.8->segmentation-models-pytorch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->torch>=1.8->segmentation-models-pytorch) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2022.12.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (2.1.3)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.3.4-cp311-cp311-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Using cached numpy-2.3.4-cp311-cp311-macosx_14_0_arm64.whl (5.4 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-2.3.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /opt/homebrew/lib/python3.11/site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/v/Library/Python/3.11/lib/python/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/v/Library/Python/3.11/lib/python/site-packages (from matplotlib) (4.39.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/v/Library/Python/3.11/lib/python/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/v/Library/Python/3.11/lib/python/site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/v/Library/Python/3.11/lib/python/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Users/v/Library/Python/3.11/lib/python/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/v/Library/Python/3.11/lib/python/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/v/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tensorflow in /opt/homebrew/lib/python3.11/site-packages (2.19.0)\n",
      "Requirement already satisfied: opencv-python in /opt/homebrew/lib/python3.11/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.11/site-packages (1.7.2)\n",
      "Requirement already satisfied: pillow in /Users/v/Library/Python/3.11/lib/python/site-packages (9.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/v/Library/Python/3.11/lib/python/site-packages (from tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (2.28.2)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (78.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/v/Library/Python/3.11/lib/python/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (3.11.1)\n",
      "Collecting numpy<2.2.0,>=1.26.0 (from tensorflow)\n",
      "  Using cached numpy-2.1.3-cp311-cp311-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/homebrew/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /opt/homebrew/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (13.3.2)\n",
      "Requirement already satisfied: namex in /opt/homebrew/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /opt/homebrew/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/homebrew/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/homebrew/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/homebrew/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Using cached numpy-2.1.3-cp311-cp311-macosx_14_0_arm64.whl (5.4 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.3.4\n",
      "    Uninstalling numpy-2.3.4:\n",
      "      Successfully uninstalled numpy-2.3.4\n",
      "Successfully installed numpy-2.1.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install segmentation-models-pytorch pytorch-lightning albumentations\n",
    "%pip install --upgrade numpy\n",
    "%pip install --upgrade matplotlib\n",
    "%pip install tensorflow opencv-python scikit-learn pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1. Convert YOLOv8 Data to U-Net Segmentation Masks\n",
    "\n",
    "Summary: Converting the YOLO bounding boxes into U-Net pixel-wise segmentation masks (integer-encoded grayscale images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import cv2\n",
    "\n",
    "# Try importing matplotlib with error handling\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    MATPLOTLIB_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"Matplotlib import failed: {e}\")\n",
    "    print(\"Continuing without matplotlib for visualization\")\n",
    "    MATPLOTLIB_AVAILABLE = False\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import glob\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficSignDataset:\n",
    "    def __init__(self, data_path, img_size=(256, 256)):\n",
    "        self.data_path = data_path\n",
    "        self.img_size = img_size\n",
    "        self.images = []\n",
    "        self.masks = []\n",
    "        \n",
    "    def find_data_directories(self):\n",
    "        \"\"\"Find train/val/test directories\"\"\"\n",
    "        possible_paths = [\n",
    "            os.path.join(self.data_path, 'train'),\n",
    "            os.path.join(self.data_path, 'Train'),\n",
    "            self.data_path  # if data is in root directory\n",
    "        ]\n",
    "        \n",
    "        for path in possible_paths:\n",
    "            if os.path.exists(path):\n",
    "                images_dir = os.path.join(path, 'images')\n",
    "                if os.path.exists(images_dir):\n",
    "                    return path\n",
    "        raise FileNotFoundError(f\"Could not find data directories in {self.data_path}\")\n",
    "    \n",
    "    def load_yolo_annotations(self, img_path, img_shape):\n",
    "        \"\"\"Convert YOLO format to segmentation mask\"\"\"\n",
    "        # Get annotation file path\n",
    "        annotation_path = img_path.replace('images', 'labels').replace('.jpg', '.txt')\n",
    "        \n",
    "        # Create empty mask\n",
    "        mask = np.zeros(img_shape[:2], dtype=np.uint8)\n",
    "        \n",
    "        if os.path.exists(annotation_path):\n",
    "            try:\n",
    "                with open(annotation_path, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                    \n",
    "                for line in lines:\n",
    "                    data = line.strip().split()\n",
    "                    if len(data) >= 5:  # YOLO format: class x_center y_center width height\n",
    "                        class_id = int(data[0])\n",
    "                        x_center, y_center, width, height = map(float, data[1:5])\n",
    "                        \n",
    "                        # Convert normalized coordinates to pixel coordinates\n",
    "                        h, w = img_shape[:2]\n",
    "                        x_center *= w\n",
    "                        y_center *= h\n",
    "                        width *= w\n",
    "                        height *= h\n",
    "                        \n",
    "                        # Calculate bounding box coordinates\n",
    "                        x1 = max(0, int(x_center - width/2))\n",
    "                        y1 = max(0, int(y_center - height/2))\n",
    "                        x2 = min(w, int(x_center + width/2))\n",
    "                        y2 = min(h, int(y_center + height/2))\n",
    "                        \n",
    "                        # Create binary mask for traffic signs\n",
    "                        if x2 > x1 and y2 > y1:  # Ensure valid coordinates\n",
    "                            mask[y1:y2, x1:x2] = 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing annotation {annotation_path}: {e}\")\n",
    "                    \n",
    "        return mask\n",
    "    \n",
    "    def load_data(self, max_samples=None):\n",
    "        \"\"\"Load images and create corresponding masks\"\"\"\n",
    "        base_path = self.find_data_directories()\n",
    "        images_dir = os.path.join(base_path, 'images')\n",
    "        \n",
    "        if not os.path.exists(images_dir):\n",
    "            # Try to find image files directly\n",
    "            image_files = glob.glob(os.path.join(base_path, '*.jpg')) + \\\n",
    "                         glob.glob(os.path.join(base_path, '*.png'))\n",
    "        else:\n",
    "            image_files = glob.glob(os.path.join(images_dir, '*.jpg')) + \\\n",
    "                         glob.glob(os.path.join(images_dir, '*.png'))\n",
    "        \n",
    "        if max_samples:\n",
    "            image_files = image_files[:max_samples]\n",
    "        \n",
    "        print(f\"Found {len(image_files)} image files\")\n",
    "        \n",
    "        for i, img_file in enumerate(image_files):\n",
    "            if i % 500 == 0:\n",
    "                print(f\"Processing image {i}/{len(image_files)}\")\n",
    "                \n",
    "            try:\n",
    "                # Load and preprocess image\n",
    "                image = cv2.imread(img_file)\n",
    "                if image is None:\n",
    "                    print(f\"Warning: Could not load image {img_file}\")\n",
    "                    continue\n",
    "                    \n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = cv2.resize(image, self.img_size)\n",
    "                image = image.astype(np.float32) / 255.0\n",
    "                \n",
    "                # Create mask\n",
    "                original_img = cv2.imread(img_file)\n",
    "                mask = self.load_yolo_annotations(img_file, original_img.shape)\n",
    "                mask = cv2.resize(mask, self.img_size, interpolation=cv2.INTER_NEAREST)\n",
    "                mask = mask.astype(np.float32)\n",
    "                \n",
    "                self.images.append(image)\n",
    "                self.masks.append(mask)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {img_file}: {e}\")\n",
    "                continue\n",
    "            \n",
    "        if len(self.images) == 0:\n",
    "            raise ValueError(\"No images were successfully loaded!\")\n",
    "            \n",
    "        self.images = np.array(self.images)\n",
    "        self.masks = np.array(self.masks)\n",
    "        self.masks = np.expand_dims(self.masks, -1)  # Add channel dimension\n",
    "        \n",
    "        print(f\"Successfully loaded {len(self.images)} images and masks\")\n",
    "        print(f\"Images shape: {self.images.shape}, Masks shape: {self.masks.shape}\")\n",
    "        \n",
    "        return self.images, self.masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_size=(256, 256, 3)):\n",
    "    \"\"\"U-Net architecture for binary segmentation\"\"\"\n",
    "    inputs = keras.Input(input_size)\n",
    "    \n",
    "    # Encoder (Contracting path)\n",
    "    # Block 1\n",
    "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    # Block 2\n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    # Block 3\n",
    "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    # Block 4 - Bottleneck\n",
    "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
    "    \n",
    "    # Decoder (Expansive path)\n",
    "    # Block 5\n",
    "    up5 = layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(conv4)\n",
    "    up5 = layers.concatenate([up5, conv3])\n",
    "    conv5 = layers.Conv2D(256, 3, activation='relu', padding='same')(up5)\n",
    "    conv5 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv5)\n",
    "    \n",
    "    # Block 6\n",
    "    up6 = layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv5)\n",
    "    up6 = layers.concatenate([up6, conv2])\n",
    "    conv6 = layers.Conv2D(128, 3, activation='relu', padding='same')(up6)\n",
    "    conv6 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv6)\n",
    "    \n",
    "    # Block 7\n",
    "    up7 = layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv6)\n",
    "    up7 = layers.concatenate([up7, conv1])\n",
    "    conv7 = layers.Conv2D(64, 3, activation='relu', padding='same')(up7)\n",
    "    conv7 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv7)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(conv7)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='U-Net')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(y_true, y_pred):\n",
    "    \"\"\"Calculate Intersection over Union\"\"\"\n",
    "    y_pred = (y_pred > 0.5).astype(np.float32)\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred) - intersection\n",
    "    return intersection / (union + 1e-7)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate precision, recall, and F1-score\"\"\"\n",
    "    y_true_flat = y_true.flatten()\n",
    "    y_pred_flat = (y_pred.flatten() > 0.5).astype(np.float32)\n",
    "    \n",
    "    precision = precision_score(y_true_flat, y_pred_flat, zero_division=0)\n",
    "    recall = recall_score(y_true_flat, y_pred_flat, zero_division=0)\n",
    "    f1 = f1_score(y_true_flat, y_pred_flat, zero_division=0)\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_path, epochs=30, batch_size=8, max_samples=1000):\n",
    "    \"\"\"Train U-Net model with simple train/validation split\"\"\"\n",
    "    \n",
    "    print(\"Loading dataset...\")\n",
    "    dataset = TrafficSignDataset(data_path)\n",
    "    X, y = dataset.load_data(max_samples=max_samples)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, shuffle=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Training samples: {X_train.shape[0]}\")\n",
    "    print(f\"Validation samples: {X_val.shape[0]}\")\n",
    "    \n",
    "    # Create model\n",
    "    print(\"Creating U-Net model...\")\n",
    "    model = unet_model()\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(\"Model summary:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Starting training...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate model\n",
    "    print(\"Evaluating model...\")\n",
    "    y_pred = model.predict(X_val)\n",
    "    iou = calculate_iou(y_val, y_pred)\n",
    "    precision, recall, f1 = calculate_metrics(y_val, y_pred)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"IoU: {iou:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    \n",
    "    return model, history, (iou, precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in TEST MODE with limited samples...\n",
      "Loading dataset...\n",
      "Error occurred: Could not find data directories in /path/to/your/dataset\n",
      "Please check your data path and dataset structure\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Update this path to your dataset location\n",
    "    data_path = \"/path/to/your/dataset\"  # Change this!\n",
    "    \n",
    "    # For testing with a small subset first\n",
    "    test_mode = True\n",
    "    \n",
    "    if test_mode:\n",
    "        print(\"Running in TEST MODE with limited samples...\")\n",
    "        model, history, metrics = train_model(\n",
    "            data_path, \n",
    "            epochs=5, \n",
    "            batch_size=4, \n",
    "            max_samples=100\n",
    "        )\n",
    "    else:\n",
    "        print(\"Running in FULL TRAINING MODE...\")\n",
    "        model, history, metrics = train_model(\n",
    "            data_path, \n",
    "            epochs=50, \n",
    "            batch_size=8, \n",
    "            max_samples=None\n",
    "        )\n",
    "    \n",
    "    # Save the model\n",
    "    model.save('traffic_sign_unet_model.h5')\n",
    "    print(\"\\nModel saved as 'traffic_sign_unet_model.h5'\")\n",
    "    \n",
    "    return model, metrics\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        model, metrics = main()\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        print(\"Please check your data path and dataset structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running quick test...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step\n",
      "Input shape: (1, 256, 256, 3)\n",
      "Output shape: (1, 256, 256, 1)\n",
      "Model test passed!\n",
      "Metrics test - IoU: 0.3341, Precision: 0.5007\n"
     ]
    }
   ],
   "source": [
    "def quick_test():\n",
    "    \"\"\"Quick test to verify the implementation works\"\"\"\n",
    "    print(\"Running quick test...\")\n",
    "    \n",
    "    # Create a simple test\n",
    "    test_input = np.random.random((1, 256, 256, 3)).astype(np.float32)\n",
    "    \n",
    "    # Test model creation\n",
    "    model = unet_model()\n",
    "    output = model.predict(test_input)\n",
    "    \n",
    "    print(f\"Input shape: {test_input.shape}\")\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "    print(\"Model test passed!\")\n",
    "    \n",
    "    # Test metrics\n",
    "    y_true = np.random.randint(0, 2, (10, 256, 256, 1)).astype(np.float32)\n",
    "    y_pred = np.random.random((10, 256, 256, 1)).astype(np.float32)\n",
    "    \n",
    "    iou = calculate_iou(y_true, y_pred)\n",
    "    precision, recall, f1 = calculate_metrics(y_true, y_pred)\n",
    "    \n",
    "    print(f\"Metrics test - IoU: {iou:.4f}, Precision: {precision:.4f}\")\n",
    "\n",
    "# Run quick test\n",
    "quick_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T22:17:52.348483Z",
     "iopub.status.busy": "2025-10-23T22:17:52.348077Z",
     "iopub.status.idle": "2025-10-23T22:18:32.391671Z",
     "shell.execute_reply": "2025-10-23T22:18:32.390219Z",
     "shell.execute_reply.started": "2025-10-23T22:17:52.348453Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# from PIL import Image, ImageDraw\n",
    "# import shutil # New import for file operations\n",
    "\n",
    "# # --- Configuration ---\n",
    "# IMG_SIZE = 416 \n",
    "# YOLO_CLASSES = ['Green Light', 'Red Light', 'Speed Limit 10', 'Speed Limit 100', 'Speed Limit 110', 'Speed Limit 120', 'Speed Limit 20', 'Speed Limit 30', 'Speed Limit 40', 'Speed Limit 50', 'Speed Limit 60', 'Speed Limit 70', 'Speed Limit 80', 'Speed Limit 90', 'Stop'] \n",
    "# YOLO_TO_UNET_MAP = {str(i): i + 1 for i in range(len(YOLO_CLASSES))}\n",
    "\n",
    "# # IMPORTANT: Ensure these paths are correct for YOUR system\n",
    "# BASE_DIR = './data/car'       # Source of original images and YOLO labels\n",
    "# OUT_DIR = './data_processed'  # Destination for new /images and /masks folders\n",
    "\n",
    "# for split in ['train', 'valid', 'test']:\n",
    "#     image_source_dir = os.path.join(BASE_DIR, split, 'images')\n",
    "#     label_dir = os.path.join(BASE_DIR, split, 'labels')\n",
    "    \n",
    "#     # Destination directories\n",
    "#     image_output_dir = os.path.join(OUT_DIR, split, 'images') # New path for images\n",
    "#     mask_output_dir = os.path.join(OUT_DIR, split, 'masks')\n",
    "    \n",
    "#     # Create all required destination folders\n",
    "#     os.makedirs(image_output_dir, exist_ok=True)\n",
    "#     os.makedirs(mask_output_dir, exist_ok=True)\n",
    "\n",
    "#     if not os.path.exists(label_dir) or not os.path.exists(image_source_dir):\n",
    "#         print(f\"Skipping {split}: Source directories not found.\")\n",
    "#         continue\n",
    "    \n",
    "#     print(f\"Processing {split} split...\")\n",
    "    \n",
    "#     for label_file in os.listdir(label_dir):\n",
    "#         if label_file.endswith('.txt'):\n",
    "#             base_name = label_file.replace('.txt', '')\n",
    "#             image_name = base_name + '.jpg' # Assuming image format is .jpg\n",
    "            \n",
    "#             # --- ACTION 1: Copy Image ---\n",
    "#             source_image_path = os.path.join(image_source_dir, image_name)\n",
    "#             destination_image_path = os.path.join(image_output_dir, image_name)\n",
    "            \n",
    "#             if os.path.exists(source_image_path):\n",
    "#                 shutil.copyfile(source_image_path, destination_image_path)\n",
    "            \n",
    "#             # --- ACTION 2: Create Mask ---\n",
    "#             mask = Image.new('L', (IMG_SIZE, IMG_SIZE), 0)\n",
    "#             draw = ImageDraw.Draw(mask)\n",
    "            \n",
    "#             with open(os.path.join(label_dir, label_file), 'r') as f:\n",
    "#                 for line in f:\n",
    "#                     parts = line.strip().split()\n",
    "#                     if len(parts) != 5: continue\n",
    "                        \n",
    "#                     yolo_id, x_c, y_c, w, h = parts[0], *map(float, parts[1:])\n",
    "#                     unet_id = YOLO_TO_UNET_MAP.get(yolo_id)\n",
    "\n",
    "#                     x_min = int((x_c - w/2) * IMG_SIZE)\n",
    "#                     y_min = int((y_c - h/2) * IMG_SIZE)\n",
    "#                     x_max = int((x_c + w/2) * IMG_SIZE)\n",
    "#                     y_max = int((y_c + h/2) * IMG_SIZE)\n",
    "\n",
    "#                     if unet_id is not None:\n",
    "#                         draw.rectangle([x_min, y_min, x_max, y_max], fill=unet_id)\n",
    "\n",
    "#             output_path = os.path.join(mask_output_dir, base_name + '.png')\n",
    "#             mask.save(output_path)\n",
    "\n",
    "# print(\"\\n✅ Data preparation complete. The 'data_processed' directory now has both /images and /masks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2. Class Weight Calculation"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4066836,
     "sourceId": 8968421,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
